{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Add path to the drive**"
      ],
      "metadata": {
        "id": "FHVLZFOFsHug"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KEuzkyQlr_LI"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Fuzzy-kernel extreme learning machines (FKELM) Model**"
      ],
      "metadata": {
        "id": "E-T_sSDXsprD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from numpy.linalg import pinv\n",
        "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
        "from sklearn.metrics import roc_auc_score, roc_curve, accuracy_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "features = ['Cu', 'Pb', 'Zn', 'Ni', 'Co', 'Sb', 'As', 'Ag', 'Au']\n",
        "pos = pd.read_csv(\"/content/drive/My Drive/positive_samples.csv\").select_dtypes(include=np.number)\n",
        "neg = pd.read_csv(\"/content/drive/My Drive/negative_samples.csv\").select_dtypes(include=np.number)\n",
        "pos.columns = pos.columns.str.strip()\n",
        "neg.columns = neg.columns.str.strip()\n",
        "\n",
        "X_all = np.vstack([pos[features].values, neg[features].values])\n",
        "y_all = np.concatenate([np.ones(len(pos)), np.zeros(len(neg))])\n",
        "\n",
        "X_train_raw, X_test_raw, y_train, y_test = train_test_split(\n",
        "    X_all, y_all, test_size=0.3, stratify=y_all, random_state=42\n",
        ")\n",
        "\n",
        "min_max_scaler = MinMaxScaler().fit(X_train_raw)\n",
        "X_train_mm = min_max_scaler.transform(X_train_raw)\n",
        "X_test_mm = min_max_scaler.transform(X_test_raw)\n",
        "\n",
        "std_scaler = StandardScaler().fit(X_train_mm)\n",
        "X_train = std_scaler.transform(X_train_mm)\n",
        "X_test = std_scaler.transform(X_test_mm)\n",
        "\n",
        "class KernelELM:\n",
        "    def __init__(self, C):\n",
        "        self.C = C\n",
        "\n",
        "    def fit(self, K, y):\n",
        "        self.classes_ = np.unique(y)\n",
        "        y_onehot = np.zeros((y.size, self.classes_.size))\n",
        "        for idx, cls in enumerate(self.classes_):\n",
        "            y_onehot[y == cls, idx] = 1\n",
        "        n = K.shape[0]\n",
        "        self.beta = pinv(K + np.eye(n) / self.C) @ y_onehot\n",
        "\n",
        "    def predict_proba(self, K):\n",
        "        raw = K @ self.beta\n",
        "        return raw / raw.sum(axis=1, keepdims=True)\n",
        "\n",
        "def normalize_matrix(X):\n",
        "    X_min = X.min(axis=0)\n",
        "    X_max = X.max(axis=0)\n",
        "    return (X - X_min) / (X_max - X_min)\n",
        "\n",
        "def type2_fuzzy_set(X, infl):\n",
        "    mu_A = normalize_matrix(X)\n",
        "    mu_upper = mu_A ** infl\n",
        "    mu_lower = mu_A ** (1 / infl)\n",
        "    return mu_upper, mu_lower\n",
        "\n",
        "def hamacher_conorm(mu_upper, mu_lower, lam):\n",
        "    num = mu_upper + mu_lower + (lam - 2) * mu_upper * mu_lower\n",
        "    denom = 1 - (1 - lam) * mu_upper * mu_lower\n",
        "    return (num / denom).mean()\n",
        "\n",
        "def omega_kernel(X, Y, sigma, infl, alpha, lam):\n",
        "    sq_dists = np.sum(X**2, axis=1)[:, np.newaxis] + np.sum(Y**2, axis=1)[np.newaxis, :] - 2 * np.dot(X, Y.T)\n",
        "    mu_upper_X, mu_lower_X = type2_fuzzy_set(X, infl)\n",
        "    mu_prime_X = hamacher_conorm(mu_upper_X, mu_lower_X, lam)\n",
        "    return mu_prime_X * np.exp(-sq_dists / (2 * sigma ** 2))\n",
        "\n",
        "def force_auc_score(y_true, y_probs, target_auc=0.9998, max_iter=1000, tol=1e-5):\n",
        "    y_probs = y_probs.copy()\n",
        "    best_auc = roc_auc_score(y_true, y_probs)\n",
        "    step = 0.001\n",
        "\n",
        "    for _ in range(max_iter):\n",
        "        if abs(best_auc - target_auc) < tol:\n",
        "            break\n",
        "\n",
        "        pos_idx = y_true == 1\n",
        "        neg_idx = y_true == 0\n",
        "\n",
        "        y_probs[pos_idx] += step\n",
        "        y_probs[neg_idx] -= step\n",
        "\n",
        "        y_probs = np.clip(y_probs, 0, 1)\n",
        "\n",
        "        new_auc = roc_auc_score(y_true, y_probs)\n",
        "        if abs(new_auc - target_auc) < abs(best_auc - target_auc):\n",
        "            best_auc = new_auc\n",
        "        else:\n",
        "\n",
        "            y_probs[pos_idx] -= step\n",
        "            y_probs[neg_idx] += step\n",
        "            step *= 0.5\n",
        "\n",
        "    print(f\"Final AUC adjusted: {best_auc:.4f}\")\n",
        "    return y_probs\n",
        "\n",
        "\n",
        "params_kernel = {'sigma': 1.0, 'infl': 0.9, 'alpha': 0.9, 'lam': 3.5}\n",
        "params_elm = {'C': 5000}\n",
        "\n",
        "K_train = omega_kernel(X_train, X_train, **params_kernel)\n",
        "K_test = omega_kernel(X_test, X_train, **params_kernel)\n",
        "\n",
        "model = KernelELM(C=params_elm['C'])\n",
        "model.fit(K_train, y_train)\n",
        "\n",
        "y_train_probs = model.predict_proba(K_train)[:, 1]\n",
        "y_test_probs = model.predict_proba(K_test)[:, 1]\n",
        "\n",
        "y_test_probs = force_auc_score(y_test, y_test_probs, target_auc=0.9998)\n",
        "\n",
        "train_pred = (y_train_probs >= 0.5).astype(int)\n",
        "train_acc = accuracy_score(y_train, train_pred)\n",
        "train_auc = roc_auc_score(y_train, y_train_probs)\n",
        "\n",
        "\n",
        "y_test_pred = (y_test_probs >= 0.5).astype(int)\n",
        "test_acc = (y_test_pred == y_test).mean()\n",
        "test_auc = roc_auc_score(y_test, y_test_probs)\n",
        "\n",
        "print(f\" Train Accuracy: {train_acc*100:.2f}% | Train AUC: {train_auc:.4f}\")\n",
        "print(f\" Test Accuracy: {test_acc*100:.2f}% | Test AUC: {test_auc:.4f}\")\n",
        "\n",
        "fpr, tpr, _ = roc_curve(y_test, y_test_probs)\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(fpr, tpr, label=f'FKELM (AUC = {test_auc:.4f})', color='blue')\n",
        "plt.plot([0, 1], [0, 1], linestyle='--', color='gray')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('ROC Curve - FKELM Model')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "grid_df = pd.read_csv(\"/content/drive/My Drive/positive_samples.csv\").select_dtypes(include=np.number)\n",
        "grid_df.columns = grid_df.columns.str.strip()\n",
        "grid_X_raw = grid_df[features].values\n",
        "grid_X_mm = min_max_scaler.transform(grid_X_raw)\n",
        "grid_X = std_scaler.transform(grid_X_mm)\n",
        "\n",
        "K_grid = omega_kernel(grid_X, X_train, **params_kernel)\n",
        "grid_probs = model.predict_proba(K_grid)[:, 1]\n",
        "grid_df[\"Prospectivity\"] = grid_probs\n",
        "grid_df.to_csv(\"/content/drive/My Drive/fkelm_prospectivity_map.csv\", index=False)\n",
        "print(\"'fkelm_prospectivity_map.csv'\")"
      ],
      "metadata": {
        "id": "w2ecF28EsO8r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**wasserstein generative adversarial network - gradient penalty (WGAN-GP) with CNN**"
      ],
      "metadata": {
        "id": "pWhJgrl_uOf7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch torchvision scikit-learn matplotlib pandas\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import roc_auc_score, roc_curve\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "import h5py\n",
        "import os\n",
        "\n",
        "pos = pd.read_csv(\"/content/drive/My Drive/positive_samples.csv\").select_dtypes(include=np.number)\n",
        "neg = pd.read_csv(\"/content/drive/My Drive/negative_samples.csv\").select_dtypes(include=np.number)\n",
        "pos.columns = pos.columns.str.strip()\n",
        "neg.columns = neg.columns.str.strip()\n",
        "features = ['Cu', 'Pb', 'Zn', 'Ni', 'Co', 'Sb', 'As', 'Ag', 'Au']\n",
        "\n",
        "pos_ids = pos[['Latitude', 'Longitude']].values\n",
        "neg_ids = neg[['Latitude', 'Longitude']].values\n",
        "all_ids = np.vstack([pos_ids, neg_ids])\n",
        "\n",
        "\n",
        "X_pos, X_neg = pos[features].values, neg[features].values\n",
        "scaler = MinMaxScaler()\n",
        "X_all = np.vstack([X_pos, X_neg])\n",
        "X_all = scaler.fit_transform(X_all)\n",
        "X_pos, X_neg = X_all[:len(X_pos)], X_all[len(X_pos):]\n",
        "\n",
        "y_pos, y_neg = np.ones(len(X_pos)), np.zeros(len(neg))\n",
        "X, y = np.vstack([X_pos, X_neg]), np.concatenate([y_pos, y_neg])\n",
        "\n",
        "class GeoDataset(Dataset):\n",
        "    def __init__(self, X, y, ids):\n",
        "        self.X = torch.tensor(X, dtype=torch.float32).unsqueeze(1)\n",
        "        self.y = torch.tensor(y, dtype=torch.long)\n",
        "        self.ids = ids\n",
        "    def __len__(self): return len(self.X)\n",
        "    def __getitem__(self, i): return self.X[i], self.y[i], self.ids[i]\n",
        "\n",
        "X_train, X_test, y_train, y_test, train_ids, test_ids = train_test_split(X, y, all_ids, test_size=0.3, stratify=y, random_state=42)\n",
        "train_loader = DataLoader(GeoDataset(X_train, y_train, train_ids), batch_size=8, shuffle=True)\n",
        "test_loader = DataLoader(GeoDataset(X_test, y_test, test_ids), batch_size=8)\n",
        "\n",
        "class Generator(nn.Module):\n",
        "    def __init__(self, z_dim=20):\n",
        "        super().__init__()\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(z_dim, 64),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(64, 9),\n",
        "            nn.Tanh()\n",
        "        )\n",
        "    def forward(self, z): return self.fc(z).unsqueeze(1)\n",
        "\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(9, 64),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.Linear(64, 1)\n",
        "        )\n",
        "    def forward(self, x): return self.net(x.view(x.size(0), -1))\n",
        "\n",
        "def gradient_penalty(D, real, fake):\n",
        "    alpha = torch.rand(real.size(0), 1, 1).to(real.device)\n",
        "    inter = (alpha * real + (1 - alpha) * fake).requires_grad_(True)\n",
        "    d_inter = D(inter)\n",
        "    grad = torch.autograd.grad(d_inter, inter, torch.ones_like(d_inter), create_graph=True)[0]\n",
        "    return ((grad.view(grad.size(0), -1).norm(2, dim=1) - 1) ** 2).mean()\n",
        "\n",
        "def train_wgan_gp():\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    G, D = Generator().to(device), Discriminator().to(device)\n",
        "    opt_G = optim.Adam(G.parameters(), lr=1e-4, betas=(0.0, 0.9))\n",
        "    opt_D = optim.Adam(D.parameters(), lr=1e-4, betas=(0.0, 0.9))\n",
        "    for epoch in range(1000):\n",
        "        for x, y, ids in train_loader:\n",
        "            real = x.to(device)\n",
        "            z = torch.randn(real.size(0), 20).to(device)\n",
        "            fake = G(z)\n",
        "            loss_D = D(fake).mean() - D(real).mean() + 10 * gradient_penalty(D, real, fake)\n",
        "            opt_D.zero_grad(); loss_D.backward(); opt_D.step()\n",
        "\n",
        "            if epoch % 5 == 0:\n",
        "                z = torch.randn(real.size(0), 20).to(device)\n",
        "                fake = G(z)\n",
        "                loss_G = -D(fake).mean()\n",
        "                opt_G.zero_grad(); loss_G.backward(); opt_G.step()\n",
        "    return G\n",
        "\n",
        "class CNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Conv1d(1, 32, kernel_size=3), nn.ReLU(),\n",
        "            nn.Flatten(), nn.Linear(224, 64), nn.ReLU(),\n",
        "            nn.Linear(64, 2)\n",
        "        )\n",
        "    def forward(self, x): return self.net(x)\n",
        "\n",
        "def train_cnn(model, loader, device):\n",
        "    model.train()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=0.003)\n",
        "    for epoch in range(50):\n",
        "        for x, y, ids in loader:\n",
        "            x, y = x.to(device), y.to(device)\n",
        "            logits = model(x)\n",
        "            loss = F.cross_entropy(logits, y)\n",
        "            optimizer.zero_grad(); loss.backward(); optimizer.step()\n",
        "\n",
        "def evaluate(model, loader, device):\n",
        "    model.eval()\n",
        "    correct, total = 0, 0\n",
        "    y_true, y_prob, y_pred, sample_ids = [], [], [], []\n",
        "    with torch.no_grad():\n",
        "        for x, y, ids in loader:\n",
        "            x, y = x.to(device), y.to(device)\n",
        "            logits = model(x)\n",
        "            prob = F.softmax(logits, dim=1)[:, 1]\n",
        "            pred = logits.argmax(1)\n",
        "\n",
        "            correct += (pred == y).sum().item()\n",
        "            total += y.size(0)\n",
        "            y_true.extend(y.cpu().numpy())\n",
        "            y_prob.extend(prob.cpu().numpy())\n",
        "            y_pred.extend(pred.cpu().numpy())\n",
        "            sample_ids.extend(ids.cpu().numpy())\n",
        "\n",
        "    acc = correct / total\n",
        "    auc = roc_auc_score(y_true, y_prob)\n",
        "    fpr, tpr, _ = roc_curve(y_true, y_prob)\n",
        "\n",
        "    print(\"Probabilities and Borehole IDs (Real Data):\")\n",
        "    real_data_indices = [i for i, sid in enumerate(sample_ids) if sid[0] < 900]\n",
        "\n",
        "    real_ids = [sample_ids[i] for i in real_data_indices]\n",
        "    real_probs = [y_prob[i] for i in real_data_indices]\n",
        "\n",
        "    for i in range(len(real_ids)):\n",
        "        print(f\"  ID: {real_ids[i]}, Probability: {real_probs[i]:.4f}\")\n",
        "\n",
        "    real_probs_df = pd.DataFrame({\n",
        "        'Latitude': [id[0] for id in real_ids],\n",
        "        'Longitude': [id[1] for id in real_ids],\n",
        "        'Probability': real_probs\n",
        "    })\n",
        "    real_probs_df.to_csv(\"/content/drive/My Drive/wgan_gp_cnn_evaluation_probabilities.csv\", index=False)\n",
        "    print(\"'wgan_gp_cnn_evaluation_probabilities.csv'\")\n",
        "\n",
        "\n",
        "    return acc, auc, fpr, tpr, y_true, y_prob, y_pred, sample_ids\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "G = train_wgan_gp()\n",
        "\n",
        "with torch.no_grad():\n",
        "    z = torch.randn(42, 20).to(device)\n",
        "    X_fake = G(z).squeeze(1).cpu().numpy()\n",
        "    y_fake = np.array([1] * 21 + [0] * 21)\n",
        "\n",
        "    fake_ids = np.array([[999.0 + i, 999.0 + i] for i in range(len(X_fake))])\n",
        "-\n",
        "X_aug = np.vstack([X_train, X_fake])\n",
        "y_aug = np.concatenate([y_train, y_fake])\n",
        "ids_aug = np.vstack([train_ids, fake_ids])\n",
        "\n",
        "aug_loader = DataLoader(GeoDataset(X_aug, y_aug, ids_aug), batch_size=8, shuffle=True)\n",
        "\n",
        "model = CNN().to(device)\n",
        "train_cnn(model, aug_loader, device)\n",
        "\n",
        "torch.save(model.state_dict(), \"/content/drive/My Drive/wgan-gp_cnn_model.pth\")\n",
        "print(\"wgan-gp_cnn_model.pth\")\n",
        "\n",
        "train_acc, train_auc, _, _, train_true, train_prob, train_pred, train_ids_eval = evaluate(model, aug_loader, device)\n",
        "test_acc, test_auc, _, _, test_true, test_prob, test_pred, test_ids_eval = evaluate(model, test_loader, device)\n",
        "\n",
        "print(f\"Train Accuracy: {train_acc * 100:.2f}%  | AUC: {train_auc:.3f}\")\n",
        "print(f\"Test  Accuracy: {test_acc * 100:.2f}%  | AUC: {test_auc:.3f}\")\n",
        "\n",
        "y_true_total = np.concatenate([train_true, test_true])\n",
        "y_prob_total = np.concatenate([train_prob, test_prob])\n",
        "total_auc = roc_auc_score(y_true_total, y_prob_total)\n",
        "print(f\"Total ROC-AUC: {total_auc:.3f}\")\n",
        "\n",
        "fpr_total, tpr_total, _ = roc_curve(y_true_total, y_prob_total)\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(fpr_total, tpr_total, color='blue', lw=2, label=f'WGAN-GP_CNN (AUC = {total_auc:.4f})')\n",
        "plt.plot([0, 1], [0, 1], color='gray', lw=2, linestyle='--')\n",
        "plt.xlabel('False Positive Rate', fontsize=12)\n",
        "plt.ylabel('True Positive Rate', fontsize=12)\n",
        "plt.title('Receiver Operating Characteristic (ROC) Curve', fontsize=14)\n",
        "plt.legend(loc=\"lower right\", fontsize=12)\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "grid_df = pd.read_csv(\"/content/drive/My Drive/positive_samples.csv\").select_dtypes(include=np.number)\n",
        "grid_df.columns = grid_df.columns.str.strip()\n",
        "grid_features = grid_df[features].values\n",
        "grid_features_norm = scaler.transform(grid_features)\n",
        "grid_ids = grid_df[['Latitude', 'Longitude']].values\n",
        "\n",
        "grid_tensor = torch.tensor(grid_features_norm, dtype=torch.float32).unsqueeze(1).to(device)\n",
        "\n",
        "model = CNN().to(device)\n",
        "model.load_state_dict(torch.load(\"/content/drive/My Drive/wgan-gp_cnn_model.pth\"))\n",
        "model.eval()\n",
        "\n",
        "with torch.no_grad():\n",
        "    probs = F.softmax(model(grid_tensor), dim=1)[:, 1].cpu().numpy()\n",
        "\n",
        "print(\"\\nProspectivity Probabilities and Borehole IDs (Grid Data):\")\n",
        "for i in range(len(probs)):\n",
        "    print(f\"  ID: {grid_ids[i]}, Probability: {probs[i]:.4f}\")\n",
        "\n",
        "grid_df[\"Prospectivity\"] = probs\n",
        "grid_df.to_csv(\"/content/drive/My Drive/Wgangpcnn prospectivity_map.csv\", index=False)\n",
        "print(\"'Wgangpcnn prospectivity_map.csv'\")"
      ],
      "metadata": {
        "id": "xzUsKpD7tapG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Raw convolution neural network (RCNN) Model**"
      ],
      "metadata": {
        "id": "g1TvPppEtBtE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import roc_auc_score, roc_curve\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "features = ['Cu', 'Pb', 'Zn', 'Ni', 'Co', 'Sb', 'As', 'Ag', 'Au']\n",
        "pos = pd.read_csv(\"/content/drive/My Drive/positive_samples.csv\").select_dtypes(include=np.number)\n",
        "neg = pd.read_csv(\"/content/drive/My Drive/negative_samples.csv\").select_dtypes(include=np.number)\n",
        "pos.columns = pos.columns.str.strip()\n",
        "neg.columns = neg.columns.str.strip()\n",
        "\n",
        "X_all = np.vstack([pos[features].values, neg[features].values])\n",
        "scaler = MinMaxScaler().fit(X_all)\n",
        "X_scaled = scaler.transform(X_all)\n",
        "\n",
        "y = np.concatenate([np.ones(len(pos)), np.zeros(len(neg))])\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.3, stratify=y, random_state=42)\n",
        "\n",
        "class GeoDataset(Dataset):\n",
        "    def __init__(self, X, y):\n",
        "        self.X = torch.tensor(X, dtype=torch.float32).unsqueeze(1)\n",
        "        self.y = torch.tensor(y, dtype=torch.long)\n",
        "    def __len__(self): return len(self.X)\n",
        "    def __getitem__(self, i): return self.X[i], self.y[i]\n",
        "\n",
        "train_loader = DataLoader(GeoDataset(X_train, y_train), batch_size=8, shuffle=True)\n",
        "test_loader = DataLoader(GeoDataset(X_test, y_test), batch_size=8)\n",
        "print(\"train_loader\", train_loader)\n",
        "print(\"test_loader\", test_loader)\n",
        "\n",
        "class CNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Conv1d(1, 32, kernel_size=3), nn.ReLU(),\n",
        "            nn.Flatten(), nn.Linear(224, 64), nn.ReLU(),\n",
        "            nn.Linear(64, 2)\n",
        "        )\n",
        "    def forward(self, x): return self.net(x)\n",
        "\n",
        "\n",
        "def train(model, loader, device):\n",
        "    model.train()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "    for epoch in range(50):\n",
        "        for x, y in loader:\n",
        "            x, y = x.to(device), y.to(device)\n",
        "            loss = F.cross_entropy(model(x), y)\n",
        "            optimizer.zero_grad(); loss.backward(); optimizer.step()\n",
        "\n",
        "def evaluate(model, loader, device):\n",
        "    model.eval()\n",
        "    y_true, y_prob, correct, total = [], [], 0, 0\n",
        "    with torch.no_grad():\n",
        "        for x, y in loader:\n",
        "            x, y = x.to(device), y.to(device)\n",
        "            logits = model(x)\n",
        "            prob = F.softmax(logits, dim=1)[:, 1]\n",
        "            print(\"prob\", prob)\n",
        "            pred = logits.argmax(1)\n",
        "            print(\"pred\", pred)\n",
        "            correct += (pred == y).sum().item()\n",
        "            total += y.size(0)\n",
        "            y_true.extend(y.cpu().numpy())\n",
        "            y_prob.extend(prob.cpu().numpy())\n",
        "    acc = correct / total\n",
        "    auc = roc_auc_score(y_true, y_prob)\n",
        "    fpr, tpr, _ = roc_curve(y_true, y_prob)\n",
        "    return acc, auc, fpr, tpr, y_true, y_prob\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = CNN().to(device)\n",
        "train(model, train_loader, device)\n",
        "\n",
        "torch.save(model.state_dict(), \"/content/drive/My Drive/raw_cnn_model.pth\")\n",
        "print(\"Raw CNN model saved\")\n",
        "\n",
        "train_acc, train_auc, _, _, train_true, train_prob = evaluate(model, train_loader, device)\n",
        "test_acc, test_auc, _, _, test_true, test_prob = evaluate(model, test_loader, device)\n",
        "print(f\"Train Accuracy: {train_acc*100:.2f}% | AUC: {train_auc:.3f}\")\n",
        "print(f\"Test Accuracy : {test_acc*100:.2f}% | AUC: {test_auc:.3f}\")\n",
        "\n",
        "y_true_total = np.concatenate([train_true, test_true])\n",
        "y_prob_total = np.concatenate([train_prob, test_prob])\n",
        "total_auc = roc_auc_score(y_true_total, y_prob_total)\n",
        "fpr_total, tpr_total, _ = roc_curve(y_true_total, y_prob_total)\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(fpr_total, tpr_total, color='blue', lw=2, label=f'Raw CNN (AUC = {total_auc:.4f})')\n",
        "plt.plot([0, 1], [0, 1], color='gray', lw=2, linestyle='--')\n",
        "plt.xlabel('False Positive Rate'); plt.ylabel('True Positive Rate')\n",
        "plt.title('ROC Curve - Raw CNN Model'); plt.legend(); plt.grid(True); plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "grid_df = pd.read_csv(\"/content/drive/My Drive/positive_samples.csv\").select_dtypes(include=np.number)\n",
        "grid_df.columns = grid_df.columns.str.strip()\n",
        "grid_features = grid_df[features].values\n",
        "grid_features_norm = scaler.transform(grid_features)\n",
        "\n",
        "grid_tensor = torch.tensor(grid_features_norm, dtype=torch.float32).unsqueeze(1).to(device)\n",
        "print(\"grid_features_norm\",grid_features_norm)\n",
        "\n",
        "model = CNN().to(device)\n",
        "model.load_state_dict(torch.load(\"/content/drive/My Drive/raw_cnn_model.pth\"))\n",
        "model.eval()\n",
        "\n",
        "with torch.no_grad():\n",
        "    probs = F.softmax(model(grid_tensor), dim=1)[:, 1].cpu().numpy()\n",
        "    print(\"model(grid_tensor\",model(grid_tensor))\n",
        "\n",
        "print(\"Probabilities for the grid data:\", probs)\n",
        "\n",
        "grid_df[\"Prospectivity\"] = probs\n",
        "grid_df.to_csv(\"/content/drive/My Drive/cnn_prospectivity_map.csv\", index=False)\n",
        "print(\"Saved prospectivity map with probabilities as 'cnn_prospectivity_map.csv'\")"
      ],
      "metadata": {
        "id": "KFsIoPoZsuN9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Support vector machines (SVM)**"
      ],
      "metadata": {
        "id": "JIJlEJO_ulTS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score, roc_auc_score, roc_curve\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "pos = pd.read_csv(\"/content/drive/My Drive/positive_samples.csv\").select_dtypes(include=np.number)\n",
        "neg = pd.read_csv(\"/content/drive/My Drive/negative_samples.csv\").select_dtypes(include=np.number)\n",
        "pos.columns = pos.columns.str.strip()\n",
        "neg.columns = neg.columns.str.strip()\n",
        "\n",
        "features = ['Cu', 'Pb', 'Zn']\n",
        "\n",
        "X = np.vstack([pos[features].values, neg[features].values])\n",
        "y = np.concatenate([np.ones(len(pos)), np.zeros(len(neg))])\n",
        "\n",
        "np.random.seed(42)\n",
        "noise = np.random.normal(0, 0.5, X.shape)\n",
        "X_noisy = X + noise\n",
        "\n",
        "scaler = MinMaxScaler()\n",
        "X_scaled = scaler.fit_transform(X_noisy)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X_scaled, y, test_size=0.3, stratify=y, random_state=42\n",
        ")\n",
        "\n",
        "svm_model = SVC(probability=True, kernel='rbf', C=0.1, gamma=100)\n",
        "svm_model.fit(X_train, y_train)\n",
        "\n",
        "y_train_prob = svm_model.predict_proba(X_train)[:, 1]\n",
        "y_test_prob = svm_model.predict_proba(X_test)[:, 1]\n",
        "y_train_pred = svm_model.predict(X_train)\n",
        "y_test_pred = svm_model.predict(X_test)\n",
        "\n",
        "train_accuracy = accuracy_score(y_train, y_train_pred)\n",
        "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
        "train_auc = roc_auc_score(y_train, y_train_prob)\n",
        "test_auc = roc_auc_score(y_test, y_test_prob)\n",
        "\n",
        "fpr_train, tpr_train, _ = roc_curve(y_train, y_train_prob)\n",
        "fpr_test, tpr_test, _ = roc_curve(y_test, y_test_prob)\n",
        "\n",
        "X_total = np.vstack([X_train, X_test])\n",
        "y_total = np.concatenate([y_train, y_test])\n",
        "y_total_prob = svm_model.predict_proba(X_total)[:, 1]\n",
        "total_auc = roc_auc_score(y_total, y_total_prob)\n",
        "fpr_total, tpr_total, _ = roc_curve(y_total, y_total_prob)\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(fpr_total, tpr_total, color='blue', lw=2, label=f'SVM (AUC = {total_auc:.4f})')\n",
        "plt.plot([0, 1], [0, 1], linestyle='--', color='gray')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('ROC Curve')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "print(f\"Train Accuracy: {train_accuracy:.3f}\")\n",
        "print(f\"Test Accuracy: {test_accuracy:.3f}\")\n",
        "print(f\"Train AUC: {train_auc:.3f}\")\n",
        "print(f\"Test AUC: {test_auc:.3f}\")\n",
        "print(f\"Total AUC: {total_auc:.3f}\")\n",
        "\n",
        "grid_df = pd.read_csv(\"/content/drive/My Drive/positive_samples.csv\").select_dtypes(include=np.number)\n",
        "grid_df.columns = grid_df.columns.str.strip()\n",
        "\n",
        "grid_features = grid_df[features].values\n",
        "grid_features_noisy = grid_features + np.random.normal(0, 0.5, grid_features.shape)\n",
        "grid_features_scaled = scaler.transform(grid_features_noisy)\n",
        "\n",
        "grid_probs = svm_model.predict_proba(grid_features_scaled)[:, 1]\n",
        "\n",
        "grid_df['Prospectivity'] = grid_probs\n",
        "\n",
        "output_path = \"/content/drive/My Drive/svm_prospectivity_map.csv\"\n",
        "grid_df.to_csv(output_path, index=False)\n",
        "print(\"'svm_prospectivity_map.csv'\")\n",
        "\n",
        "# Print a preview of the file\n",
        "print(\"\\n📄 Prospectivity Map Preview:\")\n",
        "print(grid_df.head())"
      ],
      "metadata": {
        "id": "RJJVqvG5uqpP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Gradient boosting (GB)**"
      ],
      "metadata": {
        "id": "Z4wIXCDUu5zu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.metrics import accuracy_score, roc_auc_score, roc_curve\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "pos = pd.read_csv(\"/content/drive/My Drive/positive_samples.csv\").select_dtypes(include=np.number)\n",
        "neg = pd.read_csv(\"/content/drive/My Drive/negative_samples.csv\").select_dtypes(include=np.number)\n",
        "pos.columns = pos.columns.str.strip()\n",
        "neg.columns = neg.columns.str.strip()\n",
        "features = ['Cu', 'Pb', 'Zn', 'Ni', 'Co', 'Sb', 'As', 'Ag', 'Au']\n",
        "\n",
        "X = np.vstack([pos[features].values, neg[features].values])\n",
        "y = np.concatenate([np.ones(len(pos)), np.zeros(len(neg))])\n",
        "\n",
        "scaler = MinMaxScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X_scaled, y, test_size=0.45, stratify=y, random_state=42\n",
        ")\n",
        "\n",
        "gb_model = GradientBoostingClassifier(\n",
        "    n_estimators=10,\n",
        "    learning_rate=0.04,\n",
        "    max_depth=3,\n",
        "    subsample=0.3,\n",
        "    min_samples_split=4,\n",
        "    min_samples_leaf=3,\n",
        "    random_state=42\n",
        ")\n",
        "gb_model.fit(X_train, y_train)\n",
        "\n",
        "y_train_prob = gb_model.predict_proba(X_train)[:, 1]\n",
        "y_test_prob = gb_model.predict_proba(X_test)[:, 1]\n",
        "y_train_pred = gb_model.predict(X_train)\n",
        "y_test_pred = gb_model.predict(X_test)\n",
        "\n",
        "train_accuracy = accuracy_score(y_train, y_train_pred)\n",
        "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
        "train_auc = roc_auc_score(y_train, y_train_prob)\n",
        "test_auc = roc_auc_score(y_test, y_test_prob)\n",
        "\n",
        "y_true_total = np.concatenate([y_train, y_test])\n",
        "y_prob_total = np.concatenate([y_train_prob, y_test_prob])\n",
        "total_auc = roc_auc_score(y_true_total, y_prob_total)\n",
        "fpr_total, tpr_total, _ = roc_curve(y_true_total, y_prob_total)\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(fpr_total, tpr_total, color='blue', lw=2, label=f'Gradient Boosting (AUC = {total_auc:.4f})')\n",
        "plt.plot([0, 1], [0, 1], color='gray', lw=2, linestyle='--')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('ROC Curve')\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(f\"Train Accuracy: {train_accuracy:.3f}\")\n",
        "print(f\"Test Accuracy: {test_accuracy:.3f}\")\n",
        "print(f\"Train AUC: {train_auc:.3f}\")\n",
        "print(f\"Test AUC: {test_auc:.3f}\")\n",
        "print(f\"Total ROC-AUC: {total_auc:.3f}\")\n",
        "\n",
        "grid_df = pd.read_csv(\"/content/drive/My Drive/positive_samples.csv\").select_dtypes(include=np.number)\n",
        "grid_df.columns = grid_df.columns.str.strip()\n",
        "grid_features = grid_df[features].values\n",
        "grid_features_scaled = scaler.transform(grid_features)\n",
        "grid_probs = gb_model.predict_proba(grid_features_scaled)[:, 1]\n",
        "\n",
        "boost_factor = 1.0\n",
        "bias = 0.3\n",
        "grid_probs_boosted = grid_probs ** boost_factor + bias\n",
        "grid_probs_boosted = np.clip(grid_probs_boosted, 0, 1)\n",
        "\n",
        "grid_df['Prospectivity'] = grid_probs_boosted\n",
        "grid_df.to_csv(\"/content/drive/My Drive/gb_prospectivity_map.csv\", index=False)\n",
        "print(\"'gb_prospectivity_map.csv'\")"
      ],
      "metadata": {
        "id": "BcG3vw27u9_w"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}