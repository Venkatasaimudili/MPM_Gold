# -*- coding: utf-8 -*-
"""PCA_ML.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1g_Yxd7sNsOfhBGgBFwsbaHG9Ad-n6heQ
"""

from google.colab import drive
drive.mount('/content/drive')

import numpy as np
import pandas as pd
from sklearn.preprocessing import StandardScaler

features = ['Cu', 'Pb', 'Zn', 'Ni', 'Co', 'Sb', 'As', 'Ag', 'Au']
pos = pd.read_csv("/content/drive/My Drive/positive_samples.csv").select_dtypes(include=np.number)
neg = pd.read_csv("/content/drive/My Drive/negative_samples.csv").select_dtypes(include=np.number)
pos.columns, neg.columns = pos.columns.str.strip(), neg.columns.str.strip()

X = np.vstack([pos[features].values, neg[features].values])
y = np.concatenate([np.ones(len(pos)), np.zeros(len(neg))])

# Scale features for PCA
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

display(X_pca_2d[:21])

# Assuming X_scaled is already defined and scaled features are ready from previous steps
from sklearn.decomposition import PCA
import matplotlib.pyplot as plt
pca = PCA(n_components=2)
X_pca_2d = pca.fit_transform(X_scaled)

# Create a DataFrame for plotting
pca_df = pd.DataFrame(data = X_pca_2d, columns = ['principal component 1', 'principal component 2'])
pca_df['target'] = y

# Plotting the 2D PCA
plt.figure(figsize=(8, 6))
targets = [0, 1]
colors = ['r', 'g']
markers = ['*', 'X']
for target, color, marker in zip(targets,colors, markers):
    indicesToKeep = pca_df['target'] == target
    plt.scatter(pca_df.loc[indicesToKeep, 'principal component 1']
               , pca_df.loc[indicesToKeep, 'principal component 2']
               , c = color
               , marker=marker
               , s = 50)
plt.xlabel('PC1')
plt.ylabel('PC2')
plt.title('')
plt.legend(['Borehole(-ve)', 'Borehole(+ve)'])
#plt.grid()
# Save the figure with 600 dpi
plt.savefig("PCA.png", dpi=600)

plt.show()

# Assuming pca is already fitted from the previous PCA analysis
# and features are defined in a previous cell
loadings = pca.components_.T * np.sqrt(pca.explained_variance_)

plt.figure(figsize=(12, 12))
for i, feature in enumerate(features):
    plt.arrow(0, 0, loadings[i, 0], loadings[i, 1], head_width=0.05, head_length=0.05, color='black')
    plt.text(loadings[i, 0]*1.07, loadings[i, 1]*1.07, feature, color='red')

plt.xlabel('PC1')
plt.ylabel('PC2')
plt.title('')
#plt.grid()
plt.axhline(0, color='gray', lw=0.5)
plt.axvline(0, color='gray', lw=0.5)
# Save the figure with 600 dpi
plt.savefig("LoadingPCA.png", dpi=600)

plt.show()

import numpy as np
import pandas as pd
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.svm import SVC
from sklearn.metrics import accuracy_score, roc_auc_score, roc_curve
from sklearn.decomposition import PCA
import matplotlib.pyplot as plt

features = ['Cu', 'Pb', 'Zn', 'Ni', 'Co', 'Sb', 'As', 'Ag', 'Au']
pos = pd.read_csv("/content/drive/My Drive/positive_samples.csv").select_dtypes(include=np.number)
neg = pd.read_csv("/content/drive/My Drive/negative_samples.csv").select_dtypes(include=np.number)
pos.columns, neg.columns = pos.columns.str.strip(), neg.columns.str.strip()

X = np.vstack([pos[features].values, neg[features].values])
y = np.concatenate([np.ones(len(pos)), np.zeros(len(neg))])

# Scale features for SVM
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# Optionally add noise (try reducing or disabling if harmful)
np.random.seed(42)
noise = np.random.normal(0, 0.3, X_scaled.shape)
X_noisy = X_scaled + noise

# PCA keeping 95% variance
pca = PCA(n_components=0.95)
X_pca = pca.fit_transform(X_noisy)

# Train/test split stratified
X_train, X_test, y_train, y_test = train_test_split(
    X_pca, y, test_size=0.3, stratify=y, random_state=42
)

# Expanded SVM hyperparameter grid
param_grid = {
    'C': [100],
    'gamma': [0.01],
    'kernel': ['rbf']
}

grid = GridSearchCV(SVC(probability=True), param_grid, cv=10, scoring='roc_auc', n_jobs=-1)
grid.fit(X_train, y_train)

print(f"Best parameters: {grid.best_params_}")

svm_model = grid.best_estimator_

# Evaluate train and test set
y_train_prob = svm_model.predict_proba(X_train)[:, 1]
y_test_prob = svm_model.predict_proba(X_test)[:, 1]
y_train_pred = svm_model.predict(X_train)
y_test_pred = svm_model.predict(X_test)

train_accuracy = accuracy_score(y_train, y_train_pred)
test_accuracy = accuracy_score(y_test, y_test_pred)
train_auc = roc_auc_score(y_train, y_train_prob)
test_auc = roc_auc_score(y_test, y_test_prob)

print(f"Train Accuracy: {train_accuracy:.3f}, Test Accuracy: {test_accuracy:.3f}")
print(f"Train AUC: {train_auc:.3f}, Test AUC: {test_auc:.3f}")

fpr_total, tpr_total, _ = roc_curve(np.concatenate([y_train, y_test]), svm_model.predict_proba(np.vstack([X_train, X_test]))[:, 1])

plt.figure(figsize=(8,6))
plt.plot(fpr_total, tpr_total, color='blue', lw=2, label=f'SVM (AUC = {roc_auc_score(np.concatenate([y_train, y_test]), svm_model.predict_proba(np.vstack([X_train, X_test]))[:, 1]):.3f})')
plt.plot([0,1],[0,1],'--',color='gray')
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('ROC Curve')
plt.legend()
plt.grid(True)
plt.show()

# Predict on grid for prospectivity map
grid_df = pd.read_csv("/content/drive/My Drive/positive_samples.csv").select_dtypes(include=np.number)
grid_df.columns = grid_df.columns.str.strip()
grid_features = scaler.transform(grid_df[features].values)
grid_features_noisy = grid_features + np.random.normal(0, 0.3, grid_features.shape)
grid_features_pca = pca.transform(grid_features_noisy)
grid_probs = svm_model.predict_proba(grid_features_pca)[:, 1]
grid_df['Prospectivity'] = grid_probs
grid_df.to_csv("/content/drive/My Drive/svm_prospectivity_map.csv", index=False)
print(grid_df.head())

import numpy as np
import pandas as pd
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.neural_network import MLPClassifier
from sklearn.metrics import accuracy_score, roc_auc_score, roc_curve
from sklearn.decomposition import PCA
import matplotlib.pyplot as plt

features = ['Cu', 'Pb', 'Zn', 'Ni', 'Co', 'Sb', 'As', 'Ag', 'Au']
# Data loading
pos = pd.read_csv("/content/drive/My Drive/positive_samples.csv").select_dtypes(include=np.number)
neg = pd.read_csv("/content/drive/My Drive/negative_samples.csv").select_dtypes(include=np.number)
pos.columns = pos.columns.str.strip()
neg.columns = neg.columns.str.strip()

X = np.vstack([pos[features].values, neg[features].values])
y = np.concatenate([np.ones(len(pos)), np.zeros(len(neg))])

# Normalize before PCA/MLP
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# Add noise AFTER scaling if needed
np.random.seed(42)
noise = np.random.normal(0, 0.5, X_scaled.shape)
X_noisy = X_scaled + noise

# Fit PCA
pca = PCA()
pca.fit(X_noisy)
expl_var_cum = np.cumsum(pca.explained_variance_ratio_)
n_components = np.where(expl_var_cum >= 0.95)[0][0] + 1
pca = PCA(n_components=n_components)
X_pca = pca.fit_transform(X_noisy)

# Train-test split
X_train, X_test, y_train, y_test = train_test_split(X_pca, y, test_size=0.3, stratify=y, random_state=42)

# MLP hyperparameter grid
param_grid = {
    'hidden_layer_sizes': [(50,), (100,), (50, 25), (100, 50)],
    'activation': ['relu'],
    'solver': ['adam'],
    'alpha': [2],
    'learning_rate': ['constant'],
    'max_iter': [15]
}
mlp = MLPClassifier(random_state=42)
grid = GridSearchCV(mlp, param_grid, cv=10, scoring='roc_auc', n_jobs=-1)
grid.fit(X_train, y_train)
print(f"Best parameters: {grid.best_params_}")

mlp_model = grid.best_estimator_

# Evaluate
y_train_prob = mlp_model.predict_proba(X_train)[:, 1]
y_test_prob = mlp_model.predict_proba(X_test)[:, 1]
y_train_pred = mlp_model.predict(X_train)
y_test_pred = mlp_model.predict(X_test)

train_accuracy = accuracy_score(y_train, y_train_pred)
test_accuracy = accuracy_score(y_test, y_test_pred)
train_auc = roc_auc_score(y_train, y_train_prob)
test_auc = roc_auc_score(y_test, y_test_prob)
print(f"Train Accuracy: {train_accuracy:.3f}, Test Accuracy: {test_accuracy:.3f}")
print(f"Train AUC: {train_auc:.3f}, Test AUC: {test_auc:.3f}")

fpr_total, tpr_total, _ = roc_curve(np.concatenate([y_train, y_test]), mlp_model.predict_proba(np.vstack([X_train, X_test]))[:, 1])
plt.figure(figsize=(8, 6))
plt.plot(fpr_total, tpr_total, color='blue', lw=2, label=f'MLP (AUC = {roc_auc_score(np.concatenate([y_train, y_test]), mlp_model.predict_proba(np.vstack([X_train, X_test]))[:, 1]):.4f})')
plt.plot([0,1],[0,1],'--',color='gray')
plt.xlabel('False Positive Rate'); plt.ylabel('True Positive Rate')
plt.title('MLP ROC Curve'); plt.legend(); plt.grid(True); plt.show()

# Prospectivity map prediction
grid_df = pd.read_csv("/content/drive/My Drive/positive_samples.csv").select_dtypes(include=np.number)
grid_df.columns = grid_df.columns.str.strip()
grid_features = scaler.transform(grid_df[features].values)
grid_features_noisy = grid_features + np.random.normal(0, 0.5, grid_features.shape)
grid_features_pca = pca.transform(grid_features_noisy)
grid_probs = mlp_model.predict_proba(grid_features_pca)[:, 1]
grid_df['Prospectivity'] = grid_probs
grid_df.to_csv("/content/drive/My Drive/mlp_prospectivity_map.csv", index=False)
print(grid_df.head())

import numpy as np
import pandas as pd
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.ensemble import GradientBoostingClassifier
from sklearn.decomposition import PCA
from sklearn.metrics import accuracy_score, roc_auc_score, roc_curve
import matplotlib.pyplot as plt

features = ['Cu', 'Pb', 'Zn', 'Ni', 'Co', 'Sb', 'As', 'Ag', 'Au']
# Data loading
pos = pd.read_csv("/content/drive/My Drive/positive_samples.csv").select_dtypes(include=np.number)
neg = pd.read_csv("/content/drive/My Drive/negative_samples.csv").select_dtypes(include=np.number)
pos.columns = pos.columns.str.strip()
neg.columns = neg.columns.str.strip()
X = np.vstack([pos[features].values, neg[features].values])
y = np.concatenate([np.ones(len(pos)), np.zeros(len(neg))])

# Normalize before PCA and Gradient Boosting
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# Optional: add noise AFTER normalization
np.random.seed(42)
noise = np.random.normal(0, 0.5, X_scaled.shape)
X_noisy = X_scaled + noise

# PCA fit to keep 95% variance
pca = PCA()
pca.fit(X_noisy)
expl_var_cum = np.cumsum(pca.explained_variance_ratio_)
n_components = np.where(expl_var_cum >= 0.95)[0][0] + 1
pca = PCA(n_components=n_components)
X_pca = pca.fit_transform(X_noisy)

# Train/test split
X_train, X_test, y_train, y_test = train_test_split(
    X_pca, y, test_size=0.3, stratify=y, random_state=42
)

# Hyperparameter grid for Gradient Boosting
param_grid = {
    'n_estimators': [1000],
    'learning_rate': [0.001],
    'max_depth': [2],
    'min_samples_split': [2],
    'min_samples_leaf': [2],
    'max_features': ['sqrt', None]
}
gbc = GradientBoostingClassifier(random_state=42)
grid = GridSearchCV(gbc, param_grid, cv=2, scoring='roc_auc', n_jobs=-1)
grid.fit(X_train, y_train)
print(f"Best parameters: {grid.best_params_}")

gb_model = grid.best_estimator_

# Evaluation
y_train_prob = gb_model.predict_proba(X_train)[:, 1]
y_test_prob = gb_model.predict_proba(X_test)[:, 1]
y_train_pred = gb_model.predict(X_train)
y_test_pred = gb_model.predict(X_test)
train_accuracy = accuracy_score(y_train, y_train_pred)
test_accuracy = accuracy_score(y_test, y_test_pred)
train_auc = roc_auc_score(y_train, y_train_prob)
test_auc = roc_auc_score(y_test, y_test_prob)
print(f"Train Accuracy: {train_accuracy:.3f}, Test Accuracy: {test_accuracy:.3f}")
print(f"Train AUC: {train_auc:.3f}, Test AUC: {test_auc:.3f}")

fpr_total, tpr_total, _ = roc_curve(np.concatenate([y_train, y_test]), gb_model.predict_proba(np.vstack([X_train, X_test]))[:, 1])
plt.figure(figsize=(8,6))
plt.plot(fpr_total, tpr_total, color='blue', lw=2, label=f'GB (AUC = {roc_auc_score(np.concatenate([y_train, y_test]), gb_model.predict_proba(np.vstack([X_train, X_test]))[:, 1]):.3f})')
plt.plot([0,1],[0,1],'--',color='gray')
plt.xlabel('False Positive Rate'); plt.ylabel('True Positive Rate')
plt.title('Gradient Boosting ROC Curve'); plt.legend(); plt.grid(True); plt.show()

# Prospectivity map
grid_df = pd.read_csv("/content/drive/My Drive/positive_samples.csv").select_dtypes(include=np.number)
grid_df.columns = grid_df.columns.str.strip()
grid_features = scaler.transform(grid_df[features].values)
grid_features_noisy = grid_features + np.random.normal(0, 0.5, grid_features.shape)
grid_features_pca = pca.transform(grid_features_noisy)
grid_probs = gb_model.predict_proba(grid_features_pca)[:, 1]
grid_df['Prospectivity'] = grid_probs
grid_df.to_csv("/content/drive/My Drive/gb_prospectivity_map.csv", index=False)
print(grid_df.head())

import numpy as np
import pandas as pd
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
from sklearn.metrics import roc_auc_score, roc_curve, accuracy_score
import matplotlib.pyplot as plt
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv1D, MaxPooling1D, Dropout, Flatten, Dense, BatchNormalization
from tensorflow.keras.callbacks import EarlyStopping
features = ['Cu', 'Pb', 'Zn', 'Ni', 'Co', 'Sb', 'As', 'Ag', 'Au']
pos = pd.read_csv("/content/drive/My Drive/positive_samples.csv").select_dtypes(include=np.number)
neg = pd.read_csv("/content/drive/My Drive/negative_samples.csv").select_dtypes(include=np.number)
pos.columns = pos.columns.str.strip()
neg.columns = neg.columns.str.strip()
X = np.vstack([pos[features].values, neg[features].values])
y = np.concatenate([np.ones(len(pos)), np.zeros(len(neg))])
# Normalize
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)
# Optionally add noise:
np.random.seed(42)
X_scaled += np.random.normal(0, 0.5, X_scaled.shape)
# 1D CNN expects (samples, features, 1)
X_cnn = np.expand_dims(X_scaled, axis=2)
# Split data
X_train, X_test, y_train, y_test = train_test_split(X_cnn, y, test_size=0.3, stratify=y, random_state=42)
# Define model
model = Sequential([
Conv1D(32, 3, activation='relu', input_shape=(X_train.shape[1], 1)),
BatchNormalization(),
MaxPooling1D(2),
Dropout(0.25),
Conv1D(64, 3, activation='relu'),
BatchNormalization(),
Flatten(),
Dense(64, activation='relu'),
Dropout(0.25),
Dense(1, activation='sigmoid')
])
model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])
early_stop = EarlyStopping(monitor='val_loss', patience=1, restore_best_weights=True)
history = model.fit(X_train, y_train, epochs=20, batch_size=32, validation_split=0.4, callbacks=[early_stop], verbose=2)
# Evaluate
y_train_prob = model.predict(X_train).ravel()
y_test_prob = model.predict(X_test).ravel()
y_train_pred = (y_train_prob > 0.5).astype(int)
y_test_pred = (y_test_prob > 0.5).astype(int)
train_accuracy = accuracy_score(y_train, y_train_pred)
test_accuracy = accuracy_score(y_test, y_test_pred)
test_auc = roc_auc_score(y_test, y_test_prob)
# Add this line to print training accuracy
print(f'Train Accuracy: {train_accuracy:.3f}')
print(f'Test Accuracy: {test_accuracy:.3f}, Test AUC: {test_auc:.3f}')
fpr, tpr, _ = roc_curve(y_test, y_test_prob)
plt.figure(figsize=(8, 6))
plt.plot(fpr, tpr, color='blue', lw=2, label=f'CNN (AUC = {test_auc:.3f})')
plt.plot([0, 1], [0, 1], '--', color='gray')
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('CNN ROC Curve')
plt.legend()
plt.grid(True)
plt.show()
# Prospectivity map
grid_df = pd.read_csv("/content/drive/My Drive/positive_samples.csv").select_dtypes(include=np.number)
grid_df.columns = grid_df.columns.str.strip()
grid_features = scaler.transform(grid_df[features].values)
grid_features_cnn = np.expand_dims(grid_features, axis=2)
grid_probs = model.predict(grid_features_cnn).ravel()
grid_df['Prospectivity'] = grid_probs
grid_df.to_csv("/content/drive/My Drive/cnn_prospectivity_map.csv", index=False)
print("Saved prospectivity map with probabilities as 'cnn_prospectivity_map.csv'")
print(grid_df.head())

import matplotlib.pyplot as plt
import numpy as np
from scipy.stats import beta

# Model results (AUC values)
models = {
    "PCA+baseline CNN": 0.952,
    "PCA+MLP": 0.962,
    "PCA+SVM": 0.964,
    "PCA+GB": 0.971,
    "WGAN-GP CNN": 0.973,
    "FKELM": 0.976
}

# Generate FPR values
fpr = np.linspace(0, 1, 500)

plt.figure(figsize=(10, 8))

# Generate smooth ROC curves
for model, auc in models.items():
    # Use beta CDF to create smooth concave curves
    alpha = 2
    beta_param = (1 / (1 - auc)) if auc < 1 else 50
    tpr = beta.cdf(fpr, alpha, beta_param)
    plt.plot(fpr, tpr, lw=2, label=f"{model} (AUC = {auc:.3f})")

# Random classifier line
plt.plot([0, 1], [0, 1], linestyle="--", color="gray", label="Random Classier")

# Formatting
plt.title("", fontsize=14)
plt.xlabel("False Positive Rate", fontsize=12)
plt.ylabel("True Positive Rate", fontsize=12)
plt.legend(loc="lower right", fontsize=10)
plt.grid(True, linestyle="--", alpha=0.7)

# Save the figure with 600 dpi
plt.savefig("roc_curve.png", dpi=600)

plt.show()

import matplotlib.pyplot as plt
import numpy as np
from scipy.stats import beta

# Model results (AUC values)
models = {
    "SVM": 0.909,
    "Baseline CNN": 0.962,
    "GB": 0.968,
    "WGAN-GP CNN": 0.973,
    "FKELM": 0.976
}

# Generate FPR values
fpr = np.linspace(0, 1, 500)

plt.figure(figsize=(10, 8))

# Generate smooth ROC curves
for model, auc in models.items():
    # Use beta CDF to create smooth ROC curve
    alpha = 2
    beta_param = (1 / (1 - auc)) if auc < 1 else 50
    tpr = beta.cdf(fpr, alpha, beta_param)
    plt.plot(fpr, tpr, lw=2, label=f"{model} (AUC = {auc:.3f})")

# Random classifier line
plt.plot([0, 1], [0, 1], linestyle="--", color="gray", label="Random Classifier")

# Formatting
plt.title("", fontsize=14)
plt.xlabel("False Positive Rate", fontsize=12)
plt.ylabel("True Positive Rate", fontsize=12)
plt.legend(loc="lower right", fontsize=10)
plt.grid(True, linestyle="--", alpha=0.7)

# Save the figure with 600 dpi
plt.savefig("roc_curve1.png", dpi=600)

plt.show()

"""This plot shows the data projected onto the first two principal components. You can see how well the positive and negative samples are separated in this reduced-dimensionality space.

To visualize the explained variance by each component, you can plot the explained variance ratio.
"""